{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9151244,"sourceType":"datasetVersion","datasetId":5527875}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nimport matplotlib.pyplot as plt \nimport torch.optim as optim\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport os ","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:33:54.880718Z","iopub.execute_input":"2024-08-11T18:33:54.881051Z","iopub.status.idle":"2024-08-11T18:33:54.886843Z","shell.execute_reply.started":"2024-08-11T18:33:54.881026Z","shell.execute_reply":"2024-08-11T18:33:54.885686Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load_image(path: Path) -> np.ndarray:\n    return np.array(Image.open(path))\n\ndef neglog_window(image: np.ndarray, epsilon: float = 0.01) -> np.ndarray:\n    image = np.array(image)\n    shape = image.shape\n    if len(shape) == 2:\n        image = image[np.newaxis, :, :]\n    image += image.min(axis=(1, 2), keepdims=True) + epsilon\n    image = -np.log(image)\n    image_min = image.min(axis=(1, 2), keepdims=True)\n    image_max = image.max(axis=(1, 2), keepdims=True)\n    if np.any(image_max == image_min):\n        print(\n            f\"mapping constant image to 0. This probably indicates the projector is pointed away from the volume.\"\n        )\n        image[:] = 0\n        if image.shape[0] > 1:\n            print(\"TODO: zeroed all images, even though only one might be bad.\")\n    else:\n        image = (image - image_min) / (image_max - image_min)\n\n    if np.any(np.isnan(image)):\n        print(f\"got NaN values from negative log transform.\")\n\n    if len(shape) == 2:\n        return image[0]\n    else:\n        return image\n    \n    \ndef seg_to_masks(seg: np.ndarray) -> tuple[np.ndarray, list[int], list[int]]:\n    \"\"\"Convert a binary-encoded multi-label segmentation to masks.\"\"\"\n    category_ids = []\n    fragment_ids = []\n    masks = []\n    for category_id in CATEGORIES.values():\n        for fragment_id in range(1, 11):\n            mask = np.right_shift(seg, _shift(category_id, fragment_id)) & 1\n            if mask.sum() > 0:\n                masks.append(mask)\n                category_ids.append(category_id)\n                fragment_ids.append(fragment_id)\n    return np.array(masks), category_ids, fragment_ids\n\n\ndef _shift(category_id: int, fragment_id: int) -> int:\n    return 10 * (category_id - 1) + fragment_id\n\n\ndef masks_to_seg(masks: np.ndarray, category_ids: list[int], fragment_ids: list[int]) -> np.ndarray:\n\n    seg = np.zeros((masks.shape[1], masks.shape[2]), dtype=np.uint32)\n    masks = masks.astype(np.uint32)\n    for mask, category_id, fragment_id in zip(masks, category_ids, fragment_ids):\n        seg = np.bitwise_or(seg, np.left_shift(mask, _shift(category_id, fragment_id)))\n    return seg\n\n\nCATEGORIES: dict[str, int] = {\"SA\": 1,\"LI\": 2,\"RI\": 3,}","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:33:54.958596Z","iopub.execute_input":"2024-08-11T18:33:54.958857Z","iopub.status.idle":"2024-08-11T18:33:54.975218Z","shell.execute_reply.started":"2024-08-11T18:33:54.958836Z","shell.execute_reply":"2024-08-11T18:33:54.974313Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self, n_channels=1, n_classes=30):\n        super().__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))\n        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))\n        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 512))\n        \n        self.up1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n        self.up_conv1 = DoubleConv(512, 256)\n        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.up_conv2 = DoubleConv(256, 128)\n        self.up3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.up_conv3 = DoubleConv(128, 64)\n        \n        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        \n        x = self.up1(x4)\n        x = torch.cat([x, x3], dim=1)\n        x = self.up_conv1(x)\n        x = self.up2(x)\n        x = torch.cat([x, x2], dim=1)\n        x = self.up_conv2(x)\n        x = self.up3(x)\n        x = torch.cat([x, x1], dim=1)\n        x = self.up_conv3(x)\n        \n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:33:54.976757Z","iopub.execute_input":"2024-08-11T18:33:54.977214Z","iopub.status.idle":"2024-08-11T18:33:54.992277Z","shell.execute_reply.started":"2024-08-11T18:33:54.977187Z","shell.execute_reply":"2024-08-11T18:33:54.991503Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class PENGWIN(Dataset):\n    def __init__(self, image_dir , mask_dir , start , end ,num):\n        self.image_dir =image_dir\n        self.mask_dir = mask_dir\n\n        self.image_list = sorted(os.listdir(self.image_dir))[start:end*num]\n        self.mask_list = sorted(os.listdir(self.mask_dir))[start:end*num]\n\n    def __len__(self):\n        return len(self.image_list)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.image_dir, self.image_list[index])\n        mask_path = os.path.join(self.mask_dir, self.mask_list[index])\n\n        image = load_image(img_path)\n        image = neglog_window(image)\n        image = torch.from_numpy(image).float().unsqueeze(0)  # Add channel dimension\n\n        mask = np.array(Image.open(mask_path))\n        masks, category_ids, fragment_ids = seg_to_masks(mask)\n        \n        binary_mask = np.zeros((30, 448, 448), dtype=np.float32)\n        for mask, cat_id, frag_id in zip(masks, category_ids, fragment_ids):\n            channel = (cat_id - 1) * 10 + (frag_id - 1)\n            binary_mask[channel] = mask\n        \n        binary_mask=torch.from_numpy(binary_mask).to(device)\n        \n        return image, binary_mask","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-11T18:33:54.996621Z","iopub.execute_input":"2024-08-11T18:33:54.997310Z","iopub.status.idle":"2024-08-11T18:33:55.007241Z","shell.execute_reply.started":"2024-08-11T18:33:54.997284Z","shell.execute_reply":"2024-08-11T18:33:55.006452Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"path1=\"/kaggle/input/xray-pengwin-2024/train/train/input/images/x-ray\"\npath2=\"/kaggle/input/xray-pengwin-2024/train/train/output/images/x-ray\"\n\nsize=22\n\nstart=0   # 0-100 different xray -> 100*500\nend=10\nnum=499   # num slices of same example -> 001_000 to 001_num . dont change\n\n#  total files used will be (end-start)*500 \n\ndataset = PENGWIN(path1 , path2 ,start , end , num )\ndataloader = DataLoader(dataset, batch_size=size, shuffle=True)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = UNet(n_channels=1, n_classes=30)\nmodel = model.to(device)\nmodel=nn.DataParallel(model)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.9, patience=3, verbose=True)\n\n\npath = \"/kaggle/working/\"\n\n# comment or uncomment based on weights there or not \nfile=\"epoch1000-loss0.000898.pth\"\n# file=None     \n\n\nif file!=None:\n    startepoch=epochnum(file)\n    weights=os.path.join(path , file)\n    model.load_state_dict(torch.load(weights ))\n    print(f\"loading from checkpoint , sarting from epoch {startepoch}\")\nelse:\n    startepoch=0\n    print(f\"loading no checkpoint , starting from epoch {startepoch}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:33:55.047729Z","iopub.execute_input":"2024-08-11T18:33:55.048021Z","iopub.status.idle":"2024-08-11T18:33:56.100568Z","shell.execute_reply.started":"2024-08-11T18:33:55.047999Z","shell.execute_reply":"2024-08-11T18:33:56.099641Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"loading from checkpoint , sarting from epoch 1000\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 63\n\nfor epoch in range(startepoch + 1, startepoch + epochs + 1):\n    model.train()\n    epoch_loss=0\n    count=0\n    for inputs, targets in dataloader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        epoch_loss+=loss.item()\n        count+=1\n        \n    print(f\"Epoch {epoch} of {epochs+startepoch} Loss: {epoch_loss:.6f}  , avg loss : {  epoch_loss/ count:.6f}\")\n    scheduler.step(epoch_loss)\n   \n    if epoch%5==0:\n  \n        model_filename = f\"epoch{epoch}-loss{epoch_loss:.6f}.pth\"\n        model_path = os.path.join(\"/kaggle/working\", model_filename)\n        torch.save(model.state_dict(), model_path)\n        print(f\"saved as {model_filename}\")\n    \nprint(\"Training finished!\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T18:33:56.102522Z","iopub.execute_input":"2024-08-11T18:33:56.103330Z","iopub.status.idle":"2024-08-11T18:35:05.494401Z","shell.execute_reply.started":"2024-08-11T18:33:56.103291Z","shell.execute_reply":"2024-08-11T18:35:05.493387Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1001 of 1001 Loss: 0.294632  , avg loss : 0.012810\nTraining finished!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# INFERENCE","metadata":{}},{"cell_type":"code","source":"# def predict_and_encode(model, image_path):\n#     image = load_image(image_path)\n#     image = neglog_window(image)\n#     image = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n    \n#     path=\"/kaggle/working/\"\n#     weights=os.path.join(path , \"epoch500-loss0.000312.pth\")\n#     model.eval()\n#     model.load_state_dict(torch.load(weights))\n\n#     with torch.no_grad():\n#         output = model(image.to(device))\n    \n#     binary_pred = (output.cpu().numpy()[0] > 0.5).astype(np.uint8)\n    \n#     masks = []\n#     category_ids = []\n#     fragment_ids = []\n#     for i in range(30):\n#         if np.any(binary_pred[i]):\n#             masks.append(binary_pred[i])\n#             category_ids.append((i // 10) + 1)\n#             fragment_ids.append((i % 10) + 1)\n    \n#     encoded_seg = masks_to_seg(np.array(masks), category_ids, fragment_ids)\n    \n#     return encoded_seg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_path = \"/kaggle/input/xray-pengwin-2024/Single example/001_in/001_0059.tif\"\n# predicted_seg = predict_and_encode(model, image_path)\n# Image.fromarray(predicted_seg).save(\"/kaggle/working/predicted_seg.tif\")\n# print(type(predicted_seg) , np.shape(predicted_seg))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image=Image.open(\"/kaggle/working/predicted_seg.tif\")\n# print(np.unique(image , return_counts=True))\n\n# plt.imshow(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ground=\"/kaggle/input/xray-pengwin-2024/Single example/001_out/001_0059.tif\"\n# ground_image=Image.open(ground)\n# print(np.unique(ground_image , return_counts=True))\n# plt.imshow(ground_image)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# REMOVING WEIGHTS IF NEEDED","metadata":{}},{"cell_type":"code","source":"# def epochnum(file):\n#     try:\n#         epoch_part = file.split('epoch')[1].split('-')[0]\n#         return int(epoch_part)\n#     except (IndexError, ValueError):\n#         return -1\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path = \"/kaggle/working\"\n# pth_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.pth')]\n# pth_files.sort(key=lambda x: epochnum(os.path.join(path, x)) , reverse=True)\n# # for file in pth_files[1:]:\n# # # #     if file==\"state.db\":\n# #     os.remove(os.path.join(path , file))\n# #     print(f\"removed {file}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.remove(os.path.join(path,\"predicted_seg.tif\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path = \"/kaggle/working\"\n# print(os.listdir(path))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# l=sorted(os.listdir(\"/kaggle/input/xray-pengwin-2024/train/train/input/images/x-ray\"))\n# print(l[999])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path1=\"/kaggle/input/xray-pengwin-2024/train/train/input/images/x-ray\"\n# path2=\"/kaggle/input/xray-pengwin-2024/train/train/output/images/x-ray\"\n# l1=(sorted(os.listdir(path1)))\n# l2=(sorted(os.listdir(path2)))\n# for i in range(10):\n#     print(l1[i] , l2[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}